{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c20d62700ce47505",
   "metadata": {},
   "source": [
    "# PRACTICAL Lesson  5 \n",
    "\n",
    "##MARKOV CHAINS\n",
    "\n",
    "\n",
    "## CONTENT\n",
    "\n",
    "5.1. INTRODUCTION\n",
    "\n",
    "5.2. PRACTICAL EXAMPLE. HOW A STOCK SHARE EVOLVES\n",
    "\n",
    "5.3. PROPOSED EXERCISE: WILL THE RICH BECOME RICHER AND THE POOR BECOME POORER?\n",
    "\n",
    "5.4. PROPOSED PROBLEM. SEPTEMBER 2002 EXAMINATION\n",
    "\n",
    "5.5. PROPOSED EXERCISES. REPAIRING RIVETING MACHINES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "288545b84e1946a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T18:25:10.260456607Z",
     "start_time": "2024-01-18T18:25:02.173764916Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (2.7.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.21.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx\n",
    "!pip install matplotlib\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ebf9b2dd1f012041",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T18:30:23.207229655Z",
     "start_time": "2024-01-18T18:30:23.171603741Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'box' from 'IPython.display' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\display.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[1;32mIn [54]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mipywidgets\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mwidgets\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m display, clear_output, box\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'box' from 'IPython.display' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\display.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "from markovchain import MarkovChain as drwMarkovChain\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "# module from this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a198b48f05c4839",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T18:30:23.968477567Z",
     "start_time": "2024-01-18T18:30:23.963245239Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52a2e991ce1965db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T19:03:55.295018715Z",
     "start_time": "2024-01-18T19:03:55.246836910Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MarkovChain():\n",
    "    def __init__(self, MC, names) -> None:\n",
    "        self.MC = np.array(MC)\n",
    "        self.names = names\n",
    "\n",
    "    def get_graph(self):\n",
    "        mc = drwMarkovChain(self.MC, self.names)\n",
    "        fig=mc.draw()\n",
    "\n",
    "\n",
    "    def get_transition_matrix(self):\n",
    "        return self.MC\n",
    "    \n",
    "    def get_transition_matrix_n_steps(self, n):\n",
    "        return np.linalg.matrix_power(self.MC, n)\n",
    "\n",
    "    def check_reducibility(self):\n",
    "        # Find Pt-I and check if it is irreducible\n",
    "        A = np.transpose(self.MC) - np.eye(self.MC.shape[0])\n",
    "        print(A)\n",
    "        print(np.linalg.matrix_rank(A))\n",
    "        if np.linalg.matrix_rank(A) == self.MC.shape[0]:\n",
    "            print(\"Irreducible\")\n",
    "        else:\n",
    "            print(\"Reducible\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_estimated_first_passage_times(self):\n",
    "        U =[]\n",
    "        for i in range(self.MC.shape[0]):\n",
    "            # set column i to 0\n",
    "            A= self.MC.copy()\n",
    "            A[:,i] = 0\n",
    "            # I-A\n",
    "            A = np.eye(self.MC.shape[0]) - A\n",
    "            # set b to 1\n",
    "            b = np.ones(self.MC.shape[0])\n",
    "            # solve the system of linear equations\n",
    "            x = np.linalg.solve(A, b)\n",
    "            # x = np.linalg.inv(A) * b\n",
    "            U.append(x)\n",
    "        U = np.transpose(np.array(U))\n",
    "\n",
    "        print(U)\n",
    "\n",
    "        return U\n",
    "\n",
    "    def get_probability_first_time_passage_n_steps(self, n, i, j):\n",
    "    #    f_{i j}^{(1)}=p_{i j}^{(1)}\n",
    "    # f_{i j}^{(n)}=p_{i j}^{(n)}-\\sum_{k=1}^{n-1} f_{i j}^{(k)} \\cdot p_{i j}^{(n-k)}\n",
    "\n",
    "        f=[]\n",
    "        for n1 in range(1,n+1):\n",
    "            if n1 == 1:\n",
    "                f.append(self.MC[i,j])\n",
    "            else:\n",
    "\n",
    "                f.append(self.get_transition_matrix_n_steps(n1)[i,j] - np.sum([f[k-1]*self.get_transition_matrix_n_steps(n1-k)[i,j] for k in range(1,n1)]))\n",
    "        print(f)\n",
    "        return f[-1]\n",
    "\n",
    "    def get_steady_state(self): \n",
    "        # Let P be the transition matrix of the Markov chain.\n",
    "\n",
    "        # Lets define the matrix A = P^T - I\n",
    "        A =np.transpose(self.MC) - np.eye(self.MC.shape[0])\n",
    "\n",
    "        # Add a row of ones to A at the bottom\n",
    "        A = np.vstack((A, np.ones(self.MC.shape[0])))\n",
    "\n",
    "        # define b = [0, 0, ..., 0, 1]^T\n",
    "        b = np.zeros(self.MC.shape[0])\n",
    "        b = np.append(b, 1)\n",
    "        # Solve the system of linear equations Ax = b, remember A is not square\n",
    "        x = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def get_probability_first_time_passage_n_simulations_through_simulation(self,  i, j, n_simulations):\n",
    "        # Simulate the Markov Chain\n",
    "        steps_to_j = []\n",
    "        for _ in range(n_simulations):\n",
    "            # Start in state i\n",
    "            state = i\n",
    "            # Count the number of steps\n",
    "            steps = 0\n",
    "            # Repeat until we reach state j\n",
    "            while state != j:\n",
    "                # Take a step\n",
    "                state = np.random.choice(range(self.MC.shape[0]), p=self.MC[state])\n",
    "                # Increase the number of steps\n",
    "                steps += 1\n",
    "            # Add the number of steps to the list\n",
    "            steps_to_j.append(steps)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        return np.mean(steps_to_j),steps_to_j\n",
    "\n",
    "    def draw_probability_distribution_first_time_n_simulation(self,i,j,n):\n",
    "        mean,list = self.get_probability_first_time_passage_n_simulations_through_simulation(i,j,n)\n",
    "\n",
    "        x= np.arange(1, len(list)+1)\n",
    "        y = [np.mean(list[:i]) for i in x]\n",
    "\n",
    "        # Find the probability of going from state i to state j in n steps\n",
    "\n",
    "        real=self.get_estimated_first_passage_times()[i,j]\n",
    "\n",
    "\n",
    "        plt.plot(x,y)\n",
    "        plt.plot(x,[real]*len(x))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48e4ad5ee167bde",
   "metadata": {},
   "source": [
    "\n",
    "### 5.1 INTRODUCTION\n",
    "\n",
    "In decision-making problems, the need to make decisions based on phenomena with associated uncertainty frequently arises.\n",
    "\n",
    "A stochastic process is defined as a series of aleatory variables $\\{\\mathrm{Xt}\\}$, where index $t$ takes the values of a given set $T$. For example, process $X 1, X 2, X 3, \\ldots$ can represent a change made by customers in a detergent brand name.\n",
    "\n",
    "Another simple case is that in which knowledge about the state of the system in consecutive instants prior to $t$ provides certain information on the state of the system, although this information is totally contained in the last instant. A process with these characteristics is called a Markov Process. For instance, if the change in a detergent brand name made by customers in one month depends only on their choice in the previous month.\n",
    "\n",
    "A stochastic process $\\{\\mathrm{Xt}\\}$ is a Markov Chain if it has the following characteristics:\n",
    "\n",
    "1. A finite number of states.\n",
    "2. The Markovian property. This property is the equivalent to establishing that the conditional probability of any future \"event\", given any past \"event\" and the present state, is independent of the past event and that it depends only on the current process state.\n",
    "3. Stationary transition probabilities. Having stationary transition probabilities means that the transition probabilities do not change over time.\n",
    "4. A series of initial probabilities.\n",
    "\n",
    "If the transition probabilities (in the probabilities example of customers changing from one detergent brand name (state) to another) continue to be constant with time, the Markov Process is called a Markov Chain.\n",
    "\n",
    "An example of a Markov Chain: let's consider the following model for the a share value. At the end of a given day, the price is recorded. If the share goes up, the probability of it going up tomorrow is 0.7 . If the share goes down, the probability of it going up tomorrow is only 0.5 . This is a Markov Chain where state $0(\\mathrm{e} 0)$ represents the share price going up and state 1 (e1) represents it going down. The transition Matrix is given by:\n",
    "\n",
    "| States | E0=S | E1=B |\n",
    "| :---: | :---: | :---: |\n",
    "| E0=S | 0.70 | 0.30 |\n",
    "| E1=B | 0.50 | 0.50 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ae0eac8813ee874",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T19:03:55.694066990Z",
     "start_time": "2024-01-18T19:03:55.638500613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.501 3.973 3.509 6.012]\n",
      " [1.582 3.511 5.091 7.594]\n",
      " [2.504 3.242 3.8   8.516]\n",
      " [3.501 3.973 3.509 6.012]]\n",
      "[0.184, 0.251712]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.251712"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the states and transition probabilities\n",
    "states = ['S', 'B']\n",
    "transition_probabilities = [[0, 1], [0, 1]]\n",
    "\n",
    "# \\left[\\begin{array}{cccc}\n",
    "# 0.080 & 0.184 & 0.368 & 0.368 \\\\\n",
    "# 0.632 & 0.362 & 0 & 0 \\\\\n",
    "# 0.264 & 0.368 & 0.368 & 0 \\\\\n",
    "# 0.080 & 0.184 & 0.368 & 0.368\n",
    "# \\end{array}\\right]\n",
    "\n",
    "transition_probabilities = [[0.080, 0.184, 0.368, 0.368],\n",
    "                            [0.632, 0.368, 0, 0],\n",
    "                            [0.264, 0.368, 0.368, 0],\n",
    "                            [0.080, 0.184, 0.368, 0.368]]\n",
    "states = ['A', 'B', 'C', 'D']\n",
    "\n",
    "\n",
    "\n",
    "# Create the Markov chain   \n",
    "mc = MarkovChain(transition_probabilities, states)\n",
    "\n",
    "# Draw the Markov chain\n",
    "mc.get_estimated_first_passage_times()\n",
    "mc.get_steady_state()\n",
    "mc.get_probability_first_time_passage_n_steps(2,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b5406",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d8d9382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.92   0.632  0.264  0.08 ]\n",
      " [ 0.184 -0.632  0.368  0.184]\n",
      " [ 0.368  0.    -0.632  0.368]\n",
      " [ 0.368  0.     0.    -0.632]]\n",
      "3\n",
      "Reducible\n"
     ]
    }
   ],
   "source": [
    "transition_probabilities = [[0.080, 0.184, 0.368, 0.368],\n",
    "                            [0.632, 0.368, 0, 0],\n",
    "                            [0.264, 0.368, 0.368, 0],\n",
    "                            [0.080, 0.184, 0.368, 0.368]]\n",
    "states = ['A', 'B', 'C', 'D']\n",
    "mc = MarkovChain(transition_probabilities, states)\n",
    "mc.check_reducibility()\n",
    "# mc.draw_probability_distribution_first_time_n_simulation(0,1,1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "019ffa26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(Box(children=(Button(description='Calculate Steady States', layout=Layout(flex='1 1 0%', width=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da20111a4adf482999534135b59ad9cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Widget for input text to enter the number of states of a Markov chain\n",
    "states_input = widgets.IntText(\n",
    "    value=2,\n",
    "    description='Number of States:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Function to create an n*n matrix input widget with state name inputs in both row and column\n",
    "def create_matrix_input(n):\n",
    "    matrix_children = [widgets.Text(value='', disabled=True)]  # Empty top-left corner cell\n",
    "    # Top row state names\n",
    "    matrix_children.extend([widgets.Text(value=f'State {i+1}', layout=widgets.Layout(width='auto')) for i in range(n)])\n",
    "\n",
    "    for i in range(n):\n",
    "        # Left column state names\n",
    "        matrix_children.append(widgets.Text(value=f'State {i+1}', layout=widgets.Layout(width='auto')))\n",
    "        # Row for transition matrix # let the step be 0.1\n",
    "        matrix_children.extend([widgets.FloatText(value=1/n, step=0.1,  layout=widgets.Layout(width='auto')) for _ in range(n)])\n",
    "\n",
    "    matrix_input = widgets.GridBox(\n",
    "        children=matrix_children,\n",
    "        layout=widgets.Layout(\n",
    "            width='100%',\n",
    "            grid_template_columns=f'auto {\" \".join([\"auto\"] * n)}'\n",
    "        )\n",
    "    )\n",
    "    return matrix_input\n",
    "\n",
    "# Initially, create a 2*2 matrix input widget with state names\n",
    "matrix_input = create_matrix_input(2)\n",
    "\n",
    "# Update function for the matrix input widget when the number of states changes\n",
    "def update_matrix_input(change):\n",
    "    n = change['new']\n",
    "    global matrix_input\n",
    "    matrix_input = create_matrix_input(n)\n",
    "    matrix_widget.children = [states_input, matrix_input, calc_button, draw_button, output]\n",
    "\n",
    "states_input.observe(update_matrix_input, names='value')\n",
    "\n",
    "# Button to find the steady state probabilities\n",
    "calc_button = widgets.Button(description=\"Calculate Steady States\", layout=widgets.Layout(flex='1 1 0%', width='auto'),)\n",
    "draw_button = widgets.Button(description=\"Draw Graph\", layout=widgets.Layout(flex='1 1 0%', width='auto'))\n",
    "draw_prob_button = widgets.Button(description=\"Calculate probabilitye \\n fsd\", layout=widgets.Layout(flex='1 1 0%', width='auto'))\n",
    "solve_prob_button = widgets.Button(description=\"Solve\", layout=widgets.Layout(flex='1 1 0%', width='auto'))\n",
    "# Output widget\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to handle the button click event\n",
    "def on_calc_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        n = states_input.value\n",
    "        matrix_values = [child.value for child in matrix_input.children if isinstance(child, widgets.FloatText)]\n",
    "        state_names = [child.value for child in matrix_input.children if isinstance(child, widgets.Text) and child.value != '']\n",
    "        transition_matrix = np.array(matrix_values).reshape(n, n)\n",
    "        try:\n",
    "            M = MarkovChain(transition_matrix, state_names)\n",
    "            sol = M.get_steady_state()\n",
    "            display(f\"Steady States: {sol}\")\n",
    "            return sol\n",
    "        except Exception as e:\n",
    "            display(f\"Error: {e}\")\n",
    "\n",
    "def on_draw_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        n = states_input.value\n",
    "        matrix_values = [child.value for child in matrix_input.children if isinstance(child, widgets.FloatText)]\n",
    "        state_names = [child.value for child in matrix_input.children if isinstance(child, widgets.Text) and child.value != '']\n",
    "        # get unique state names\n",
    "        state_names = list(set(state_names))\n",
    "        transition_matrix = np.array(matrix_values).reshape(n, n)\n",
    "        try:\n",
    "            M = MarkovChain(transition_matrix, state_names)\n",
    "            M.get_graph()\n",
    "        except Exception as e:\n",
    "            display(f\"Error: {e}\")\n",
    "n = states_input.value\n",
    "\n",
    "matrix_values = [child.value for child in matrix_input.children if isinstance(child, widgets.FloatText)]\n",
    "state_names = [child.value for child in matrix_input.children if isinstance(child, widgets.Text) and child.value != '']\n",
    "# get unique state names\n",
    "state_names = list(set(state_names))\n",
    "transition_matrix = np.array(matrix_values).reshape(n, n)\n",
    "\n",
    "# Create three input widgets for a sub query\n",
    "i_input = widgets.Dropdown(\n",
    "    options=state_names,\n",
    "    description='From:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "j_input = widgets.Dropdown(\n",
    "    options=state_names,\n",
    "    description='To:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "n_input = widgets.IntText(\n",
    "    value=2,\n",
    "    description='Number of Steps:',\n",
    "        style={'description_width': 'initial'})\n",
    "def on_draw_prob_button_clicked(b):\n",
    "    n = states_input.value\n",
    "    global matrix_input\n",
    "\n",
    "  \n",
    "    matrix_widget.children = [states_input, matrix_input, calc_button, draw_button, draw_prob_button, i_input, j_input, n_input,solve_prob_button, output]\n",
    "\n",
    "def solve_prob_button_clicked(b):\n",
    "    try:\n",
    "        with output:\n",
    "            clear_output()\n",
    "            matrix_values = [child.value for child in matrix_input.children if isinstance(child, widgets.FloatText)]\n",
    "            state_names = [child.value for child in matrix_input.children if isinstance(child, widgets.Text) and child.value != '']\n",
    "            # get unique state names\n",
    "            state_names = list(set(state_names))\n",
    "            transition_matrix = np.array(matrix_values).reshape(n, n)\n",
    "            M = MarkovChain(transition_matrix, state_names)\n",
    "            display(i_input.value)\n",
    "            display(j_input.value)\n",
    "            display(n_input.value)\n",
    "            # Get the index of the state names\n",
    "            i = state_names.index(i_input.value)\n",
    "            j = state_names.index(j_input.value)\n",
    "            display(M.get_probability_first_time_passage_n_steps(n_input.value,i,j))\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "box_layout = widgets.Layout(display='flex',\n",
    "                    flex_flow='row',\n",
    "                    align_items='stretch')\n",
    "items_0 = [calc_button,draw_button,  draw_prob_button]\n",
    "box_0 = widgets.Box(children=items_0, layout=box_layout)\n",
    "\n",
    "calc_button.on_click(on_calc_button_clicked)\n",
    "draw_button.on_click(on_draw_button_clicked)\n",
    "draw_prob_button.on_click(on_draw_prob_button_clicked)\n",
    "solve_prob_button.on_click(solve_prob_button_clicked)\n",
    "\n",
    "# Layout the widgets\n",
    "matrix_widget = widgets.VBox([box_0, states_input, matrix_input,   output])\n",
    "display(matrix_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ebe2f356f8ca41",
   "metadata": {},
   "source": [
    "\n",
    "### 5.2 PRACTICAL EXAMPLE: HOW A STOCK SHARE EVOLVES\n",
    "\n",
    "A Stock Market analyst has observed the evolution of an electronic products firm's shares over the last few months, and concludes that this evolution can be modelled with a Markov Chain.\n",
    "\n",
    "The probability that the share goes up or down on a given day depends on what has happened on the 2 previous days:\n",
    "\n",
    "Indeed, if the share went up on 2 days (today and yesterday), the probability of it going up tomorrow is 0.9 . If it went up today but went down yesterday, the probability of it going up tomorrow is 0.6 . If it went down today but went up yesterday, the probability of it going up tomorrow is 0.5 . Finally, if it went down on the last 2 days, the probability of it going up tomorrow is 0.3 .\n",
    "\n",
    "## QUESTIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f70d8822433950",
   "metadata": {},
   "source": [
    "\n",
    "### What are the Markov Chain states?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f4c25f68ca4f47",
   "metadata": {},
   "source": [
    "\n",
    "### What is the one-step transition probabilities matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce95451fcb7575b",
   "metadata": {},
   "source": [
    "\n",
    "(The next questions must be solved with the help of the CaDMGip software)\n",
    "\n",
    "- What is the probability of a share going up or down on a given day?\n",
    "- What is the probability of a share that went up yesterday and today going down the day after tomorrow?\n",
    "- The transition probabilities matrix with 2, 3,10 and 30 steps\n",
    "- The first-passage times matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce71fc0514c91b2",
   "metadata": {},
   "source": [
    "\n",
    "### 5.3 PROPOSED EXERCISE: WILL THE RICH BECOME RICHER, AND THE POOR BECOME POORER?\n",
    "\n",
    "During the 1992 American presidential campaign, the Democrat candidate, Bill Clinton, defending he would raise taxes for the \"rich\" and would give some relief to tax payers earning average and low salaries.\n",
    "\n",
    "One of the US Treasury's functions is to study tax proposals and to determine how they could affect the country (the economy, distribution of the population's income, and other concepts). One of the studies conducted by this Department, based on 14,351 tax payers and tax declarations between 1979 and 1988, discovered that a\n",
    "considerable number of Americans on low income would move up on the income scale, while those who were higher up on the income scale would stay where they were.\n",
    "\n",
    "The data in Table 1 are the percentages of tax payers who moved between the various levels of income at the end of the decade (adjusted by inflation). For instance, $47.3 \\%$ of tax payers who earned $\\$ 200,000$ or more at the beginning of the decade remained in this category at the end of this period; the income of $38.6 \\%$ of tax payers went down to the next category (between $\\$ 45,000$ and $\\$ 199,000$ ); the income of $7.7 \\%$ went down and fell within the $\\$ 25,000-44,900$ range, and even $2.2 \\%$ earned the income of \"poor people, that is, less than $\\$ 7,000$.\n",
    "\n",
    "| Table 1. Shift in Income |  |  |  |  |  |  |  |\n",
    "| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "|  | Income at the end of the decade |  |  |  |  |  |  |\n",
    "| Income at the <br> beginning of <br> the decade | $\\$ 200,000$ <br> or more | $\\$ 45,000$ <br> to <br> $\\$ 199,999$ | $\\$ 25,000$ to <br> $\\$ 44,999$ | $\\$ 15,000$ to <br> $\\$ 24,999$ | $\\$ 7,000$ to <br> $\\$ 14,999$ | Less than <br> $\\$ 7,000$ |  |\n",
    "| $\\$ 200,000$ or <br> more | $47.3 \\%$ | $38.6 \\%$ | $7.7 \\%$ | $3.8 \\%$ | $0.4 \\%$ | $2.2 \\%$ |  |\n",
    "| $\\$ 45,000$ to <br> $\\$ 199,999$ | 5.3 | 59.4 | 20.3 | 9.4 | 4.4 | 1.2 |  |\n",
    "| $\\$ 25,000$ to <br> $\\$ 44,999$ | 0.6 | 34.8 | 37.5 | 14.8 | 9.3 | 3.0 |  |\n",
    "| $\\$ 15,000$ to <br> $\\$ 24,999$ | 0.4 | 14.6 | 32.3 | 33.0 | 14.0 | 5.7 |  |\n",
    "| $\\$ 7,000$ to <br> $\\$ 14,999$ | 0.3 | 10.8 | 19.5 | 29.6 | 29.0 | 10.8 |  |\n",
    "| Less than <br> $\\$ 7,000$ | 0.3 | 14.4 | 25.3 | 25.0 | 20.7 | 14.3 |  |\n",
    "\n",
    "Sarah $\\mathrm{Hu}$, a senior analyst in a non-profit institute, has been assigned a project to analyse the distribution of the US population's income, and also the effect that the various proposed taxes might have. Recently, some groups have shown an interest in stressing that in the USA, \"the rich are becoming richer and the poor are becoming poorer\". Ms. Hu has been commissioned to determine whether she can shed some light on this matter with the results of the US Treasury Study. She feels particularly intrigued by the similarity between Table 1 and some Markov Processes that she studied when she was at University.\n",
    "\n",
    "Ms. Hu has estimated that, currently, $1 \\%$ of the US population earns more than $\\$ 200,000$; $19 \\%$ earn between $\\$ 45,000$ and $\\$ 199,000$; the income of $20 \\%$ falls between $\\$ 25,000$ and $\\$ 44,999$; the earnings of $20 \\%$ fall within the $\\$ 15,000-24,999$ range; another $20 \\%$ earn somewhere between $\\$ 7,000$ and $\\$ 14,999$; finally, the income of $20 \\%$ is below $\\$ 7,000$.\n",
    "\n",
    "## QUESTIONS:\n",
    "\n",
    "1. What are the Markov Chain states?\n",
    "2. Based on the data in Table 1, what will the long-term income distribution be?\n",
    "3. What percentage of the population who earn less than $\\$ 7,000$ will earn more than $\\$ 200,000$ after 20 years? What is the percentage for $\\$ 100,000$ ?\n",
    "4. What is the expected number of years that the tax payers who earn under $\\$ 7,000$ will earn more than $\\$ 200,000$ ? And $\\$ 100,000$ ?\n",
    "5. How has the income distribution changed in relation to the initial income distribution?\n",
    "6. Using the CADMGIP tool to help you, respond to the question that the problem considers; will the rich become richer, and the poor become poorer?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243e5980176cc24",
   "metadata": {},
   "source": [
    "\n",
    "### 5.4 PROPOSED PROBLEM.\n",
    "\n",
    "At the beginning of each year, my car can be in a good, regular or bad state. There is a $90 \\%$ probability of a good car still being good at the beginning of the next year, a $5 \\%$ one of it being in a regular state, and a $5 \\%$ one of it being in a bad state. There is s 70\\% probability that a car in a regular state will still be regular at the beginning of the next year, and a $30 \\%$ one that it will be in a bad state. It costs 12,000 to buy a good car, 5,000 euros to buy a regular car (5000 euros is also the price to sell it), but a bad car has no sale value and must be immediately replaced with a good car. The cost to maintain a car in a good state is 1,000 euros a year, and 2,000 euros a year for a car in a regular state. Let's assume that the cost to run a car per year depends on the type of car the driver has at the beginning of the year..\n",
    "\n",
    "Let's assume that a car in a bad state only happens at the end of a year, and then (at the beginning of the next year) the car in a bad state \"must be replaced immediately\". Should I replace my car as soon as it is in a regular state, or should I wait until it is in a bad state? To solve this matter:\n",
    "\n",
    "a) Define the Markov chains for the three states (Good, Regular and Bad at the beginning of the year) for all the replacement policies (Policy A: Replace when the car is in a bad state; Policy B: Replace when the car is in a regular state).\n",
    "\n",
    "b) Obtain the steady-state probabilities.\n",
    "\n",
    "c) Determine the mean cost per year for each replacement policy.\n",
    "\n",
    "d) What replacement policy would you recommend?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732af7f2f6502396",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 5.5 PROPOSED EXERCISE. REPAIRING RIVETING MACHINES\n",
    "\n",
    "On a daily basis, a maintenance technician of a given firm checks adjustments on an automatic machine that produces rivets for the air-sea industry, among other tasks.\n",
    "\n",
    "By checking a certain number of rivets, he knows that it is not necessary to adjust the machine (A), it requires slight adjustment (B), some adjustment (C) or considerable adjustment (D).\n",
    "\n",
    "The technician has verified that if the machine is in state A, there is an $80 \\%$ probability that it will remain in this state until the next day, and a $20 \\%$ probability that it will enter state $B$.\n",
    "\n",
    "If the machine is in state $B$, there is a $70 \\%$ probability that it will remain in this state until the next day, and a $5 \\%$ probability that it will require considerable adjustment.\n",
    "\n",
    "If the machine is in state $\\mathrm{C}$, there is a $50 \\%$ probability that it will require considerable adjustment, and it is quite certain that its state will not improve.\n",
    "\n",
    "If the machine requires considerable adjustment, it will remain in this state permanently.\n",
    "\n",
    "However, the technician's job does not consist in stopping and observing the machine; instead, if the machine is found to be in state $D$, it must be adjusted. Nevertheless, the technician is not clear if when the machine is in any of the other states what interests the firm more from an economic perspective.\n",
    "\n",
    "This is because a complete adjustment costs 20,000 m.u. If the machine is in state A and begins to work at the beginning of the day, it will not produce any extra cost through loss of quality. If the technician adjusts it in state $B$, the cost for the firm is 5,000 m.u. that day, and it is 8,000 m.u. if the machine is in state C.\n",
    "\n",
    "The maintenance technician needs to economically evaluate if it is less costly to also adjust the machine completely when it is in state C.\n",
    "\n",
    "a) Model the problem with Markov Chains (one per maintenance policy) $(40 \\%)$\n",
    "\n",
    "b) Which policy is less costly? (40\\%)\n",
    "\n",
    "c) What would the adjustment cost be so that the answer to question b) would have been the opposite? $(10 \\%)$\n",
    "\n",
    "d) With the original maintenance policy, what is the expected firstpassage time from state $D$ to state $A$ ? What is the recurrence time of state $D$ ? (10\\%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d2fcceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91501486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2f72d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
